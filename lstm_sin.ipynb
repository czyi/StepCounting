{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1180c4210>, '_model_dir': 'Models/model_2', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_save_summary_steps': 100, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from Models/model_2/model.ckpt-40000\n",
      "INFO:tensorflow:Saving checkpoints for 40001 into Models/model_2/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.47379e-06, step = 40001\n",
      "INFO:tensorflow:global_step/sec: 331.374\n",
      "INFO:tensorflow:loss = 2.7048e-06, step = 40101 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.029\n",
      "INFO:tensorflow:loss = 3.73053e-06, step = 40201 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.563\n",
      "INFO:tensorflow:loss = 4.05145e-06, step = 40301 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.53\n",
      "INFO:tensorflow:loss = 3.71903e-06, step = 40401 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.792\n",
      "INFO:tensorflow:loss = 3.83235e-06, step = 40501 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.654\n",
      "INFO:tensorflow:loss = 3.86149e-06, step = 40601 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.06\n",
      "INFO:tensorflow:loss = 1.96242e-06, step = 40701 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.536\n",
      "INFO:tensorflow:loss = 3.69169e-06, step = 40801 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.701\n",
      "INFO:tensorflow:loss = 2.92164e-06, step = 40901 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.506\n",
      "INFO:tensorflow:loss = 4.00757e-06, step = 41001 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.039\n",
      "INFO:tensorflow:loss = 3.83905e-06, step = 41101 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.734\n",
      "INFO:tensorflow:loss = 3.28291e-06, step = 41201 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.559\n",
      "INFO:tensorflow:loss = 3.20265e-06, step = 41301 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.247\n",
      "INFO:tensorflow:loss = 4.02296e-06, step = 41401 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.842\n",
      "INFO:tensorflow:loss = 4.0595e-06, step = 41501 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.499\n",
      "INFO:tensorflow:loss = 3.73568e-06, step = 41601 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.59\n",
      "INFO:tensorflow:loss = 3.21197e-06, step = 41701 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.973\n",
      "INFO:tensorflow:loss = 2.83072e-06, step = 41801 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.513\n",
      "INFO:tensorflow:loss = 3.83168e-06, step = 41901 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.608\n",
      "INFO:tensorflow:loss = 2.83584e-06, step = 42001 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.912\n",
      "INFO:tensorflow:loss = 3.44839e-06, step = 42101 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.783\n",
      "INFO:tensorflow:loss = 3.52506e-06, step = 42201 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.102\n",
      "INFO:tensorflow:loss = 2.81428e-06, step = 42301 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.644\n",
      "INFO:tensorflow:loss = 2.02142e-06, step = 42401 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.246\n",
      "INFO:tensorflow:loss = 3.10944e-06, step = 42501 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.687\n",
      "INFO:tensorflow:loss = 3.76845e-06, step = 42601 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.955\n",
      "INFO:tensorflow:loss = 4.33072e-06, step = 42701 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.375\n",
      "INFO:tensorflow:loss = 3.95467e-06, step = 42801 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.834\n",
      "INFO:tensorflow:loss = 3.60631e-06, step = 42901 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.908\n",
      "INFO:tensorflow:loss = 3.64543e-06, step = 43001 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.281\n",
      "INFO:tensorflow:loss = 4.75893e-06, step = 43101 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.336\n",
      "INFO:tensorflow:loss = 2.71373e-06, step = 43201 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.347\n",
      "INFO:tensorflow:loss = 4.0308e-06, step = 43301 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.124\n",
      "INFO:tensorflow:loss = 2.68246e-06, step = 43401 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.077\n",
      "INFO:tensorflow:loss = 3.85252e-06, step = 43501 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.259\n",
      "INFO:tensorflow:loss = 2.74878e-06, step = 43601 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.125\n",
      "INFO:tensorflow:loss = 3.00134e-06, step = 43701 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.821\n",
      "INFO:tensorflow:loss = 2.78738e-06, step = 43801 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.472\n",
      "INFO:tensorflow:loss = 3.5948e-06, step = 43901 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.139\n",
      "INFO:tensorflow:loss = 3.21068e-06, step = 44001 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.448\n",
      "INFO:tensorflow:loss = 2.56483e-06, step = 44101 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.175\n",
      "INFO:tensorflow:loss = 3.41079e-06, step = 44201 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.992\n",
      "INFO:tensorflow:loss = 3.80612e-06, step = 44301 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.077\n",
      "INFO:tensorflow:loss = 3.06309e-06, step = 44401 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.957\n",
      "INFO:tensorflow:loss = 3.1105e-06, step = 44501 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.164\n",
      "INFO:tensorflow:loss = 3.02791e-06, step = 44601 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.964\n",
      "INFO:tensorflow:loss = 3.22803e-06, step = 44701 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.315\n",
      "INFO:tensorflow:loss = 4.34162e-06, step = 44801 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.305\n",
      "INFO:tensorflow:loss = 3.065e-06, step = 44901 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.934\n",
      "INFO:tensorflow:loss = 2.99628e-06, step = 45001 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.053\n",
      "INFO:tensorflow:loss = 2.00944e-06, step = 45101 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.734\n",
      "INFO:tensorflow:loss = 3.44105e-06, step = 45201 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.604\n",
      "INFO:tensorflow:loss = 3.04963e-06, step = 45301 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.853\n",
      "INFO:tensorflow:loss = 3.36909e-06, step = 45401 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.895\n",
      "INFO:tensorflow:loss = 3.83435e-06, step = 45501 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.142\n",
      "INFO:tensorflow:loss = 2.34289e-06, step = 45601 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.533\n",
      "INFO:tensorflow:loss = 4.29072e-06, step = 45701 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.59\n",
      "INFO:tensorflow:loss = 3.97371e-06, step = 45801 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.853\n",
      "INFO:tensorflow:loss = 3.69057e-06, step = 45901 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.18\n",
      "INFO:tensorflow:loss = 2.06946e-06, step = 46001 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.231\n",
      "INFO:tensorflow:loss = 3.9871e-06, step = 46101 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.48\n",
      "INFO:tensorflow:loss = 3.47862e-06, step = 46201 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.926\n",
      "INFO:tensorflow:loss = 2.84675e-06, step = 46301 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.331\n",
      "INFO:tensorflow:loss = 2.73888e-06, step = 46401 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.472\n",
      "INFO:tensorflow:loss = 3.23781e-06, step = 46501 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.364\n",
      "INFO:tensorflow:loss = 2.19718e-06, step = 46601 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.273\n",
      "INFO:tensorflow:loss = 4.27518e-06, step = 46701 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.266\n",
      "INFO:tensorflow:loss = 3.6587e-06, step = 46801 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.043\n",
      "INFO:tensorflow:loss = 2.46869e-06, step = 46901 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.815\n",
      "INFO:tensorflow:loss = 3.6831e-06, step = 47001 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.604\n",
      "INFO:tensorflow:loss = 3.66e-06, step = 47101 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.357\n",
      "INFO:tensorflow:loss = 3.14145e-06, step = 47201 (0.220 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 355.991\n",
      "INFO:tensorflow:loss = 3.07711e-06, step = 47301 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.423\n",
      "INFO:tensorflow:loss = 2.82055e-06, step = 47401 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.743\n",
      "INFO:tensorflow:loss = 3.03083e-06, step = 47501 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.963\n",
      "INFO:tensorflow:loss = 2.46231e-06, step = 47601 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.991\n",
      "INFO:tensorflow:loss = 3.72102e-06, step = 47701 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.719\n",
      "INFO:tensorflow:loss = 4.35092e-06, step = 47801 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.751\n",
      "INFO:tensorflow:loss = 3.29385e-06, step = 47901 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.404\n",
      "INFO:tensorflow:loss = 4.04725e-06, step = 48001 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.049\n",
      "INFO:tensorflow:loss = 3.90292e-06, step = 48101 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.282\n",
      "INFO:tensorflow:loss = 2.85937e-06, step = 48201 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.297\n",
      "INFO:tensorflow:loss = 3.07798e-06, step = 48301 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.396\n",
      "INFO:tensorflow:loss = 3.59627e-06, step = 48401 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.764\n",
      "INFO:tensorflow:loss = 3.73951e-06, step = 48501 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.604\n",
      "INFO:tensorflow:loss = 2.83486e-06, step = 48601 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.046\n",
      "INFO:tensorflow:loss = 3.9629e-06, step = 48701 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.155\n",
      "INFO:tensorflow:loss = 2.74321e-06, step = 48801 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.003\n",
      "INFO:tensorflow:loss = 3.34181e-06, step = 48901 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.032\n",
      "INFO:tensorflow:loss = 2.2601e-06, step = 49001 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.911\n",
      "INFO:tensorflow:loss = 4.14391e-06, step = 49101 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.367\n",
      "INFO:tensorflow:loss = 3.99673e-06, step = 49201 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.241\n",
      "INFO:tensorflow:loss = 2.8284e-06, step = 49301 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.622\n",
      "INFO:tensorflow:loss = 3.78093e-06, step = 49401 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.863\n",
      "INFO:tensorflow:loss = 3.31153e-06, step = 49501 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.88\n",
      "INFO:tensorflow:loss = 3.25635e-06, step = 49601 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.866\n",
      "INFO:tensorflow:loss = 3.16893e-06, step = 49701 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.269\n",
      "INFO:tensorflow:loss = 2.74462e-06, step = 49801 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.75\n",
      "INFO:tensorflow:loss = 2.7374e-06, step = 49901 (0.304 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 50000 into Models/model_2/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3.18444e-06.\n",
      "INFO:tensorflow:Restoring parameters from Models/model_2/model.ckpt-50000\n",
      "Mean Square Error is:0.001768\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Legend' object has no attribute 'savefig'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-87dfbed83ba3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mpic01\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplot_predicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'real_sin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mpic01\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'temp.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Legend' object has no attribute 'savefig'"
     ]
    }
   ],
   "source": [
    "# 以下程序为预测离散化之后的sin函数\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "# 加载matplotlib工具包，使用该工具包可以对预测的sin函数曲线进行绘图\n",
    "#import matplotlib as mpl\n",
    "from tensorflow.contrib.learn.python.learn.estimators.estimator import SKCompat\n",
    "#mpl.use('Agg')\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "from matplotlib import pyplot as plt\n",
    "learn = tf.contrib.learn\n",
    "HIDDEN_SIZE = 30  # Lstm中隐藏节点的个数\n",
    "NUM_LAYERS = 2  # LSTM的层数\n",
    "TIMESTEPS = 10  # 循环神经网络的截断长度\n",
    "TRAINING_STEPS = 10000  # 训练轮数\n",
    "BATCH_SIZE = 32  # batch大小\n",
    "\n",
    "TRAINING_EXAMPLES = 10000  # 训练数据个数\n",
    "TESTING_EXAMPLES = 1000  # 测试数据个数\n",
    "SAMPLE_GAP = 0.01  # 采样间隔\n",
    "# 定义生成正弦数据的函数\n",
    "def generate_data(seq):\n",
    "    X = []\n",
    "    Y = []\n",
    "    # 序列的第i项和后面的TIMESTEPS-1项合在一起作为输入;第i+TIMESTEPS项作为输出\n",
    "    # 即用sin函数前面的TIMESTPES个点的信息，预测第i+TIMESTEPS个点的函数值\n",
    "    for i in range(len(seq) - TIMESTEPS - 1):\n",
    "        X.append([seq[i:i + TIMESTEPS]])\n",
    "        Y.append([seq[i + TIMESTEPS]])\n",
    "    return np.array(X, dtype=np.float32), np.array(Y, dtype=np.float32)\n",
    "\n",
    "def LstmCell():\n",
    "    lstm_cell = rnn.BasicLSTMCell(HIDDEN_SIZE,state_is_tuple=True)\n",
    "    return lstm_cell\n",
    "\n",
    "# 定义lstm模型\n",
    "def lstm_model(X, y):\n",
    "    cell = rnn.MultiRNNCell([LstmCell() for _ in range(NUM_LAYERS)])\n",
    "    output, _ = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "    output = tf.reshape(output, [-1, HIDDEN_SIZE])\n",
    "    # 通过无激活函数的全连接层计算线性回归，并将数据压缩成一维数组结构\n",
    "    predictions = tf.contrib.layers.fully_connected(output, 1, None)\n",
    "    \n",
    "    # 将predictions和labels调整统一的shape\n",
    "    labels = tf.reshape(y, [-1])\n",
    "    predictions = tf.reshape(predictions, [-1])\n",
    "    \n",
    "    loss = tf.losses.mean_squared_error(predictions, labels)\n",
    "    train_op = tf.contrib.layers.optimize_loss(loss, tf.train.get_global_step(),\n",
    "                                             optimizer=\"Adagrad\",\n",
    "                                             learning_rate=0.1)\n",
    "    return predictions, loss, train_op\n",
    "\n",
    "# 进行训练\n",
    "# 封装之前定义的lstm\n",
    "regressor = SKCompat(learn.Estimator(model_fn=lstm_model, model_dir=\"Models/model_2\"))\n",
    "# 生成数据\n",
    "test_start = TRAINING_EXAMPLES * SAMPLE_GAP\n",
    "test_end = (TRAINING_EXAMPLES + TESTING_EXAMPLES) * SAMPLE_GAP\n",
    "train_X, train_y = generate_data(np.sin(np.linspace(0, test_start, TRAINING_EXAMPLES, dtype=np.float32)))\n",
    "test_X, test_y = generate_data(np.sin(np.linspace(test_start, test_end, TESTING_EXAMPLES, dtype=np.float32)))\n",
    "# 拟合数据\n",
    "regressor.fit(train_X, train_y, batch_size=BATCH_SIZE, steps=TRAINING_STEPS)\n",
    "# 计算预测值\n",
    "predicted = [[pred] for pred in regressor.predict(test_X)]\n",
    "\n",
    "# 计算MSE\n",
    "rmse = np.sqrt(((predicted - test_y) ** 2).mean(axis=0))\n",
    "print(\"Mean Square Error is:%f\" % rmse[0])\n",
    "\n",
    "plot_predicted, = plt.plot(predicted, label='predicted')\n",
    "plot_test, = plt.plot(test_y, label='real_sin')\n",
    "plt.legend([plot_predicted, plot_test],['predicted', 'real_sin'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicted, = plt.plot(predicted, label='predicted')\n",
    "# plot_test, = plt.plot(test_y, label='real_sin')\n",
    "# plt.legend([plot_predicted, plot_test],['predicted', 'real_sin'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_predicted, = plt.plot(predicted, label='predicted')\n",
    "# plot_test, = plt.plot(test_y, label='real_sin')\n",
    "# plt.legend([plot_predicted, plot_test],['predicted', 'real_sin'])\n",
    "\n",
    "pic01 = plt.figure(figsize=(19, 12))\n",
    "plt.plot([i for i in range(len(predicted))], [i[0] for i in predicted], 'ro')\n",
    "plt.plot([i for i in range(len(test_y))], [i[0] for i in test_y], 'bo')\n",
    "plt.show()\n",
    "pic01.savefig('temp.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.41675103],\n",
       " [-0.40750104],\n",
       " [-0.39821219],\n",
       " [-0.38888556],\n",
       " [-0.37952238],\n",
       " [-0.37012362],\n",
       " [-0.36069065],\n",
       " [-0.35122108],\n",
       " [-0.3417207],\n",
       " [-0.3321898],\n",
       " [-0.32262927],\n",
       " [-0.31304049],\n",
       " [-0.30342507],\n",
       " [-0.29378444],\n",
       " [-0.28411835],\n",
       " [-0.27442807],\n",
       " [-0.26471478],\n",
       " [-0.2549786],\n",
       " [-0.24522142],\n",
       " [-0.23544435],\n",
       " [-0.22564851],\n",
       " [-0.21583484],\n",
       " [-0.20600449],\n",
       " [-0.19615845],\n",
       " [-0.18629773],\n",
       " [-0.17642328],\n",
       " [-0.16653621],\n",
       " [-0.15663749],\n",
       " [-0.14672807],\n",
       " [-0.13680895],\n",
       " [-0.12688111],\n",
       " [-0.1169454],\n",
       " [-0.1070029],\n",
       " [-0.097054452],\n",
       " [-0.087100998],\n",
       " [-0.077143416],\n",
       " [-0.06718269],\n",
       " [-0.057219625],\n",
       " [-0.047251597],\n",
       " [-0.03728421],\n",
       " [-0.027317449],\n",
       " [-0.017352149],\n",
       " [-0.007389456],\n",
       " [0.0025694743],\n",
       " [0.012523517],\n",
       " [0.022473127],\n",
       " [0.032417279],\n",
       " [0.042355161],\n",
       " [0.052287094],\n",
       " [0.062211283],\n",
       " [0.072126895],\n",
       " [0.082033128],\n",
       " [0.091929197],\n",
       " [0.10181433],\n",
       " [0.11168772],\n",
       " [0.12154859],\n",
       " [0.13139614],\n",
       " [0.14122961],\n",
       " [0.15104821],\n",
       " [0.16085112],\n",
       " [0.17063761],\n",
       " [0.18040684],\n",
       " [0.19015807],\n",
       " [0.19989046],\n",
       " [0.20960328],\n",
       " [0.21929567],\n",
       " [0.22896689],\n",
       " [0.23861605],\n",
       " [0.24824242],\n",
       " [0.25784516],\n",
       " [0.26742661],\n",
       " [0.27698201],\n",
       " [0.28651094],\n",
       " [0.29601258],\n",
       " [0.3054859],\n",
       " [0.31492978],\n",
       " [0.32434303],\n",
       " [0.33372605],\n",
       " [0.34307772],\n",
       " [0.35239708],\n",
       " [0.36168456],\n",
       " [0.37093824],\n",
       " [0.38015723],\n",
       " [0.38934052],\n",
       " [0.39848733],\n",
       " [0.40759671],\n",
       " [0.41666776],\n",
       " [0.42569953],\n",
       " [0.43469119],\n",
       " [0.44364166],\n",
       " [0.45255011],\n",
       " [0.46141559],\n",
       " [0.47023714],\n",
       " [0.47901392],\n",
       " [0.48774481],\n",
       " [0.49642897],\n",
       " [0.50506544],\n",
       " [0.5136534],\n",
       " [0.52219164],\n",
       " [0.53067935],\n",
       " [0.53911561],\n",
       " [0.54750198],\n",
       " [0.55583447],\n",
       " [0.56411237],\n",
       " [0.57233459],\n",
       " [0.58050013],\n",
       " [0.58860791],\n",
       " [0.59665662],\n",
       " [0.60464633],\n",
       " [0.61257619],\n",
       " [0.62044477],\n",
       " [0.62825263],\n",
       " [0.63599789],\n",
       " [0.64367944],\n",
       " [0.65129673],\n",
       " [0.65884864],\n",
       " [0.66633439],\n",
       " [0.67375308],\n",
       " [0.68110389],\n",
       " [0.68838596],\n",
       " [0.69559842],\n",
       " [0.70274061],\n",
       " [0.70981163],\n",
       " [0.71681052],\n",
       " [0.72373676],\n",
       " [0.73058939],\n",
       " [0.73736793],\n",
       " [0.74407136],\n",
       " [0.75069898],\n",
       " [0.75725019],\n",
       " [0.76372427],\n",
       " [0.77012044],\n",
       " [0.77643979],\n",
       " [0.78267986],\n",
       " [0.78883982],\n",
       " [0.79491895],\n",
       " [0.80091649],\n",
       " [0.80683213],\n",
       " [0.81266493],\n",
       " [0.81841463],\n",
       " [0.82408094],\n",
       " [0.82966322],\n",
       " [0.83516163],\n",
       " [0.84057498],\n",
       " [0.84590286],\n",
       " [0.85114479],\n",
       " [0.85630041],\n",
       " [0.86136919],\n",
       " [0.86635041],\n",
       " [0.87124389],\n",
       " [0.87604934],\n",
       " [0.88076603],\n",
       " [0.8853941],\n",
       " [0.88993239],\n",
       " [0.89438128],\n",
       " [0.89873999],\n",
       " [0.90300852],\n",
       " [0.90718621],\n",
       " [0.91127276],\n",
       " [0.91526794],\n",
       " [0.91917181],\n",
       " [0.92298359],\n",
       " [0.92670321],\n",
       " [0.93033147],\n",
       " [0.93386686],\n",
       " [0.93730921],\n",
       " [0.94065845],\n",
       " [0.943914],\n",
       " [0.94707578],\n",
       " [0.95014346],\n",
       " [0.95311713],\n",
       " [0.95599675],\n",
       " [0.95878178],\n",
       " [0.96147287],\n",
       " [0.96406925],\n",
       " [0.96657097],\n",
       " [0.96897763],\n",
       " [0.9712894],\n",
       " [0.97350597],\n",
       " [0.97562718],\n",
       " [0.97765291],\n",
       " [0.97958308],\n",
       " [0.98141778],\n",
       " [0.98315662],\n",
       " [0.98479968],\n",
       " [0.98634672],\n",
       " [0.98779792],\n",
       " [0.98915279],\n",
       " [0.99041158],\n",
       " [0.99157417],\n",
       " [0.99264044],\n",
       " [0.99361002],\n",
       " [0.99448347],\n",
       " [0.99526036],\n",
       " [0.99594092],\n",
       " [0.99652463],\n",
       " [0.99701166],\n",
       " [0.99740207],\n",
       " [0.99769568],\n",
       " [0.9978925],\n",
       " [0.99799216],\n",
       " [0.99799538],\n",
       " [0.9979015],\n",
       " [0.99771065],\n",
       " [0.99742299],\n",
       " [0.99703848],\n",
       " [0.99655718],\n",
       " [0.99597871],\n",
       " [0.99530333],\n",
       " [0.99453098],\n",
       " [0.99366176],\n",
       " [0.99269527],\n",
       " [0.99163193],\n",
       " [0.99047184],\n",
       " [0.98921478],\n",
       " [0.98786056],\n",
       " [0.98640966],\n",
       " [0.98486185],\n",
       " [0.98321718],\n",
       " [0.98147565],\n",
       " [0.97963744],\n",
       " [0.97770256],\n",
       " [0.97567099],\n",
       " [0.97354275],\n",
       " [0.97131783],\n",
       " [0.96899676],\n",
       " [0.9665783],\n",
       " [0.96406376],\n",
       " [0.96145296],\n",
       " [0.95874614],\n",
       " [0.95594323],\n",
       " [0.95304465],\n",
       " [0.95005047],\n",
       " [0.94696057],\n",
       " [0.94377506],\n",
       " [0.94049442],\n",
       " [0.93711805],\n",
       " [0.93364674],\n",
       " [0.93008024],\n",
       " [0.9264192],\n",
       " [0.92266345],\n",
       " [0.91881335],\n",
       " [0.91486895],\n",
       " [0.91083062],\n",
       " [0.90669864],\n",
       " [0.90247321],\n",
       " [0.89815456],\n",
       " [0.8937428],\n",
       " [0.88923848],\n",
       " [0.88464177],\n",
       " [0.87995303],\n",
       " [0.87517256],\n",
       " [0.87030065],\n",
       " [0.86533761],\n",
       " [0.86028397],\n",
       " [0.85513985],\n",
       " [0.84990609],\n",
       " [0.84458119],\n",
       " [0.83916759],\n",
       " [0.83366513],\n",
       " [0.82807511],\n",
       " [0.82239747],\n",
       " [0.81663311],\n",
       " [0.81078249],\n",
       " [0.80484587],\n",
       " [0.79882377],\n",
       " [0.79271674],\n",
       " [0.78652483],\n",
       " [0.78024888],\n",
       " [0.77388978],\n",
       " [0.76744813],\n",
       " [0.76092458],\n",
       " [0.75431967],\n",
       " [0.74763423],\n",
       " [0.74086899],\n",
       " [0.73402458],\n",
       " [0.72710168],\n",
       " [0.72010124],\n",
       " [0.71302396],\n",
       " [0.70587063],\n",
       " [0.69864208],\n",
       " [0.69133914],\n",
       " [0.68396264],\n",
       " [0.67651337],\n",
       " [0.66899228],\n",
       " [0.6614005],\n",
       " [0.65373856],\n",
       " [0.6460076],\n",
       " [0.6382063],\n",
       " [0.63033807],\n",
       " [0.62240392],\n",
       " [0.61440486],\n",
       " [0.60634214],\n",
       " [0.59821671],\n",
       " [0.59002995],\n",
       " [0.5817821],\n",
       " [0.57347441],\n",
       " [0.56510782],\n",
       " [0.55668247],\n",
       " [0.54820025],\n",
       " [0.53966218],\n",
       " [0.53106946],\n",
       " [0.52242315],\n",
       " [0.51372439],\n",
       " [0.50497425],\n",
       " [0.4961738],\n",
       " [0.48732424],\n",
       " [0.47842669],\n",
       " [0.46948224],\n",
       " [0.46049196],\n",
       " [0.4514572],\n",
       " [0.44237888],\n",
       " [0.43325818],\n",
       " [0.42409635],\n",
       " [0.4148944],\n",
       " [0.40565354],\n",
       " [0.39637482],\n",
       " [0.38705933],\n",
       " [0.37770838],\n",
       " [0.36831993],\n",
       " [0.35889876],\n",
       " [0.34944558],\n",
       " [0.33996165],\n",
       " [0.33044821],\n",
       " [0.32090658],\n",
       " [0.31133807],\n",
       " [0.30174279],\n",
       " [0.29212189],\n",
       " [0.28247643],\n",
       " [0.27280638],\n",
       " [0.26311362],\n",
       " [0.25339925],\n",
       " [0.24366434],\n",
       " [0.23390986],\n",
       " [0.22413678],\n",
       " [0.21434616],\n",
       " [0.2045389],\n",
       " [0.19471601],\n",
       " [0.18487844],\n",
       " [0.17502712],\n",
       " [0.16516298],\n",
       " [0.15528701],\n",
       " [0.14540008],\n",
       " [0.13550308],\n",
       " [0.12559696],\n",
       " [0.11568258],\n",
       " [0.10576083],\n",
       " [0.095832571],\n",
       " [0.085898697],\n",
       " [0.075960033],\n",
       " [0.066017464],\n",
       " [0.056068368],\n",
       " [0.04611804],\n",
       " [0.036166593],\n",
       " [0.026214898],\n",
       " [0.016264018],\n",
       " [0.0063151009],\n",
       " [-0.003630735],\n",
       " [-0.013574019],\n",
       " [-0.023513667],\n",
       " [-0.033448927],\n",
       " [-0.043380134],\n",
       " [-0.053305462],\n",
       " [-0.063224122],\n",
       " [-0.073135257],\n",
       " [-0.083038136],\n",
       " [-0.092931941],\n",
       " [-0.10281582],\n",
       " [-0.11268903],\n",
       " [-0.12255077],\n",
       " [-0.13240018],\n",
       " [-0.14223649],\n",
       " [-0.15205887],\n",
       " [-0.16186652],\n",
       " [-0.17165859],\n",
       " [-0.18143435],\n",
       " [-0.19119282],\n",
       " [-0.20093329],\n",
       " [-0.21065484],\n",
       " [-0.22035663],\n",
       " [-0.23003788],\n",
       " [-0.23969771],\n",
       " [-0.24933867],\n",
       " [-0.25895518],\n",
       " [-0.26854742],\n",
       " [-0.27811444],\n",
       " [-0.28765523],\n",
       " [-0.29716831],\n",
       " [-0.30665261],\n",
       " [-0.31610852],\n",
       " [-0.325535],\n",
       " [-0.33493108],\n",
       " [-0.34429681],\n",
       " [-0.3536303],\n",
       " [-0.36293077],\n",
       " [-0.37219727],\n",
       " [-0.3814286],\n",
       " [-0.39062411],\n",
       " [-0.39978278],\n",
       " [-0.40890348],\n",
       " [-0.41798556],\n",
       " [-0.4270277],\n",
       " [-0.43602926],\n",
       " [-0.44498914],\n",
       " [-0.4539063],\n",
       " [-0.46277994],\n",
       " [-0.471609],\n",
       " [-0.48039258],\n",
       " [-0.48912954],\n",
       " [-0.49781913],\n",
       " [-0.50646031],\n",
       " [-0.51505202],\n",
       " [-0.52359343],\n",
       " [-0.53208649],\n",
       " [-0.54052615],\n",
       " [-0.54891235],\n",
       " [-0.55724406],\n",
       " [-0.56552047],\n",
       " [-0.57373995],\n",
       " [-0.58190143],\n",
       " [-0.59000504],\n",
       " [-0.59804988],\n",
       " [-0.60603499],\n",
       " [-0.61396021],\n",
       " [-0.62182373],\n",
       " [-0.6296249],\n",
       " [-0.63736284],\n",
       " [-0.64503658],\n",
       " [-0.65264529],\n",
       " [-0.66018802],\n",
       " [-0.66766405],\n",
       " [-0.67507255],\n",
       " [-0.68241286],\n",
       " [-0.68968368],\n",
       " [-0.69688457],\n",
       " [-0.70401484],\n",
       " [-0.7110734],\n",
       " [-0.71805978],\n",
       " [-0.72497296],\n",
       " [-0.73181248],\n",
       " [-0.73857743],\n",
       " [-0.74526721],\n",
       " [-0.75188094],\n",
       " [-0.75841808],\n",
       " [-0.76488048],\n",
       " [-0.7712636],\n",
       " [-0.77756804],\n",
       " [-0.78379315],\n",
       " [-0.78993821],\n",
       " [-0.79600215],\n",
       " [-0.80198443],\n",
       " [-0.80788499],\n",
       " [-0.81370354],\n",
       " [-0.81943941],\n",
       " [-0.82509249],\n",
       " [-0.83066159],\n",
       " [-0.83614647],\n",
       " [-0.84154654],\n",
       " [-0.84686118],\n",
       " [-0.8520903],\n",
       " [-0.85723305],\n",
       " [-0.86228919],\n",
       " [-0.86725825],\n",
       " [-0.87213975],\n",
       " [-0.87693328],\n",
       " [-0.88163847],\n",
       " [-0.88625509],\n",
       " [-0.89078248],\n",
       " [-0.89522034],\n",
       " [-0.89956868],\n",
       " [-0.90382659],\n",
       " [-0.90799415],\n",
       " [-0.91207081],\n",
       " [-0.91605663],\n",
       " [-0.91995084],\n",
       " [-0.92375469],\n",
       " [-0.92746592],\n",
       " [-0.93108487],\n",
       " [-0.93461132],\n",
       " [-0.93804502],\n",
       " [-0.94138503],\n",
       " [-0.94463146],\n",
       " [-0.94778466],\n",
       " [-0.95084417],\n",
       " [-0.95380986],\n",
       " [-0.95668173],\n",
       " [-0.9594593],\n",
       " [-0.96214247],\n",
       " [-0.96473086],\n",
       " [-0.96722472],\n",
       " [-0.96962345],\n",
       " [-0.97192717],\n",
       " [-0.97413576],\n",
       " [-0.97624886],\n",
       " [-0.97826648],\n",
       " [-0.98018849],\n",
       " [-0.98201466],\n",
       " [-0.98374474],\n",
       " [-0.9853791],\n",
       " [-0.98691726],\n",
       " [-0.98835921],\n",
       " [-0.98970485],\n",
       " [-0.99095416],\n",
       " [-0.9921068],\n",
       " [-0.99316299],\n",
       " [-0.99412239],\n",
       " [-0.99498522],\n",
       " [-0.99575162],\n",
       " [-0.99642086],\n",
       " [-0.99699318],\n",
       " [-0.99746859],\n",
       " [-0.99784684],\n",
       " [-0.99812806],\n",
       " [-0.998312],\n",
       " [-0.9983989],\n",
       " [-0.99838865],\n",
       " [-0.99828124],\n",
       " [-0.99807656],\n",
       " [-0.99777472],\n",
       " [-0.99737561],\n",
       " [-0.99687934],\n",
       " [-0.9962858],\n",
       " [-0.99559474],\n",
       " [-0.99480665],\n",
       " [-0.99392128],\n",
       " [-0.99293876],\n",
       " [-0.99185872],\n",
       " [-0.99068165],\n",
       " [-0.9894073],\n",
       " [-0.98803592],\n",
       " [-0.9865675],\n",
       " [-0.9850018],\n",
       " [-0.98333907],\n",
       " [-0.98157942],\n",
       " [-0.97972298],\n",
       " [-0.97776949],\n",
       " [-0.97571933],\n",
       " [-0.97357225],\n",
       " [-0.9713279],\n",
       " [-0.96898735],\n",
       " [-0.96655023],\n",
       " [-0.9640168],\n",
       " [-0.96138728],\n",
       " [-0.95866191],\n",
       " [-0.95584059],\n",
       " [-0.95292342],\n",
       " [-0.94991052],\n",
       " [-0.94680202],\n",
       " [-0.94359791],\n",
       " [-0.94029844],\n",
       " [-0.93690407],\n",
       " [-0.93341458],\n",
       " [-0.92983043],\n",
       " [-0.92615163],\n",
       " [-0.9223786],\n",
       " [-0.91851151],\n",
       " [-0.9145503],\n",
       " [-0.91049564],\n",
       " [-0.90634757],\n",
       " [-0.90210629],\n",
       " [-0.89777207],\n",
       " [-0.89334548],\n",
       " [-0.88882637],\n",
       " [-0.88421547],\n",
       " [-0.87951291],\n",
       " [-0.87471884],\n",
       " [-0.86983389],\n",
       " [-0.86485845],\n",
       " [-0.85979277],\n",
       " [-0.85463524],\n",
       " [-0.84938908],\n",
       " [-0.84405398],\n",
       " [-0.83863044],\n",
       " [-0.83311886],\n",
       " [-0.82751989],\n",
       " [-0.8218345],\n",
       " [-0.81606209],\n",
       " [-0.81020349],\n",
       " [-0.80425942],\n",
       " [-0.79822958],\n",
       " [-0.79211521],\n",
       " [-0.78591669],\n",
       " [-0.77963483],\n",
       " [-0.77326995],\n",
       " [-0.76682287],\n",
       " [-0.76029396],\n",
       " [-0.7536844],\n",
       " [-0.74699444],\n",
       " [-0.7402246],\n",
       " [-0.73337609],\n",
       " [-0.72644919],\n",
       " [-0.71944505],\n",
       " [-0.71236396],\n",
       " [-0.70520705],\n",
       " [-0.6979748],\n",
       " [-0.69066834],\n",
       " [-0.68328816],\n",
       " [-0.67583525],\n",
       " [-0.6683104],\n",
       " [-0.66071451],\n",
       " [-0.65304589],\n",
       " [-0.64530897],\n",
       " [-0.63750392],\n",
       " [-0.62963158],\n",
       " [-0.62169296],\n",
       " [-0.61368948],\n",
       " [-0.60562241],\n",
       " [-0.59749162],\n",
       " [-0.58929825],\n",
       " [-0.58104324],\n",
       " [-0.57272696],\n",
       " [-0.56435132],\n",
       " [-0.55591691],\n",
       " [-0.54742515],\n",
       " [-0.53887689],\n",
       " [-0.53027332],\n",
       " [-0.52161551],\n",
       " [-0.51290447],\n",
       " [-0.50414133],\n",
       " [-0.49532729],\n",
       " [-0.48646331],\n",
       " [-0.47755045],\n",
       " [-0.46859002],\n",
       " [-0.4595831],\n",
       " [-0.45053077],\n",
       " [-0.44143426],\n",
       " [-0.43229461],\n",
       " [-0.42311293],\n",
       " [-0.41389054],\n",
       " [-0.40462846],\n",
       " [-0.39532769],\n",
       " [-0.38598615],\n",
       " [-0.3766098],\n",
       " [-0.36719853],\n",
       " [-0.35775352],\n",
       " [-0.34827608],\n",
       " [-0.33876783],\n",
       " [-0.32923025],\n",
       " [-0.31966311],\n",
       " [-0.31006765],\n",
       " [-0.30044508],\n",
       " [-0.29079562],\n",
       " [-0.28112113],\n",
       " [-0.27142286],\n",
       " [-0.2617017],\n",
       " [-0.25195891],\n",
       " [-0.24219547],\n",
       " [-0.2324125],\n",
       " [-0.222611],\n",
       " [-0.21279205],\n",
       " [-0.20295675],\n",
       " [-0.19310601],\n",
       " [-0.18324091],\n",
       " [-0.17336252],\n",
       " [-0.16347174],\n",
       " [-0.15356955],\n",
       " [-0.14365706],\n",
       " [-0.13373511],\n",
       " [-0.12380476],\n",
       " [-0.11386685],\n",
       " [-0.10392237],\n",
       " [-0.093972281],\n",
       " [-0.084017456],\n",
       " [-0.07405521],\n",
       " [-0.06409134],\n",
       " [-0.054125704],\n",
       " [-0.044159196],\n",
       " [-0.034192987],\n",
       " [-0.024228245],\n",
       " [-0.014266193],\n",
       " [-0.0043062642],\n",
       " [0.0056503862],\n",
       " [0.015602987],\n",
       " [0.025551837],\n",
       " [0.035495095],\n",
       " [0.045431938],\n",
       " [0.055361561],\n",
       " [0.065283172],\n",
       " [0.075195961],\n",
       " [0.085099123],\n",
       " [0.094991907],\n",
       " [0.10487347],\n",
       " [0.11474307],\n",
       " [0.12459991],\n",
       " [0.13444319],\n",
       " [0.14427212],\n",
       " [0.15408593],\n",
       " [0.16388386],\n",
       " [0.17366508],\n",
       " [0.18342884],\n",
       " [0.1931743],\n",
       " [0.20290074],\n",
       " [0.21260731],\n",
       " [0.2222932],\n",
       " [0.23196092],\n",
       " [0.24160552],\n",
       " [0.25122672],\n",
       " [0.26082367],\n",
       " [0.27039534],\n",
       " [0.27994061],\n",
       " [0.28945845],\n",
       " [0.29894912],\n",
       " [0.3084116],\n",
       " [0.31784505],\n",
       " [0.32724988],\n",
       " [0.33662403],\n",
       " [0.3459667],\n",
       " [0.35527706],\n",
       " [0.36455417],\n",
       " [0.37379718],\n",
       " [0.3830052],\n",
       " [0.39217734],\n",
       " [0.40131265],\n",
       " [0.41041023],\n",
       " [0.41946924],\n",
       " [0.42848867],\n",
       " [0.43746763],\n",
       " [0.44640517],\n",
       " [0.45530051],\n",
       " [0.46415246],\n",
       " [0.47296023],\n",
       " [0.48172283],\n",
       " [0.49043941],\n",
       " [0.49910897],\n",
       " [0.50773048],\n",
       " [0.51630569],\n",
       " [0.52483046],\n",
       " [0.53330427],\n",
       " [0.54172587],\n",
       " [0.55009413],\n",
       " [0.55840808],\n",
       " [0.5666666],\n",
       " [0.57486939],\n",
       " [0.58301568],\n",
       " [0.59110427],\n",
       " [0.59913552],\n",
       " [0.60710734],\n",
       " [0.61501896],\n",
       " [0.62286961],\n",
       " [0.63065815],\n",
       " [0.63838375],\n",
       " [0.64604557],\n",
       " [0.65364259],\n",
       " [0.66117406],\n",
       " [0.66863912],\n",
       " [0.67603689],\n",
       " [0.68336654],\n",
       " [0.69062716],\n",
       " [0.69781792],\n",
       " [0.70493823],\n",
       " [0.71198684],\n",
       " [0.71896344],\n",
       " [0.72586703],\n",
       " [0.73269677],\n",
       " [0.73945212],\n",
       " [0.74613208],\n",
       " [0.75273806],\n",
       " [0.75926697],\n",
       " [0.7657184],\n",
       " [0.77209133],\n",
       " [0.77838528],\n",
       " [0.78459918],\n",
       " [0.79073256],\n",
       " [0.79678518],\n",
       " [0.80275631],\n",
       " [0.80864561],\n",
       " [0.81445307],\n",
       " [0.8201775],\n",
       " [0.8258183],\n",
       " [0.83137518],\n",
       " [0.83684731],\n",
       " [0.84223425],\n",
       " [0.84753561],\n",
       " [0.8527509],\n",
       " [0.85787946],\n",
       " [0.86292118],\n",
       " [0.86787528],\n",
       " [0.87274158],\n",
       " [0.87751973],\n",
       " [0.882209],\n",
       " [0.88680911],\n",
       " [0.89131987],\n",
       " [0.89574087],\n",
       " [0.90007174],\n",
       " [0.90431195],\n",
       " [0.90846133],\n",
       " [0.91251981],\n",
       " [0.9164868],\n",
       " [0.92036319],\n",
       " [0.92414725],\n",
       " [0.92783916],\n",
       " [0.93143845],\n",
       " [0.93494463],\n",
       " [0.93835747],\n",
       " [0.94167709],\n",
       " [0.94490296],\n",
       " [0.94803524],\n",
       " [0.95107365],\n",
       " [0.95401847],\n",
       " [0.95686913],\n",
       " [0.9596253],\n",
       " [0.96228707],\n",
       " [0.96485424],\n",
       " [0.96732652],\n",
       " [0.96970379],\n",
       " [0.97198606],\n",
       " [0.97417313],\n",
       " [0.97626483],\n",
       " [0.97826105],\n",
       " [0.98016161],\n",
       " [0.98196661],\n",
       " [0.98367584],\n",
       " [0.98528916],\n",
       " [0.98680639],\n",
       " [0.98822773],\n",
       " [0.98955297],\n",
       " [0.99078196],\n",
       " [0.99191469],\n",
       " [0.99295092],\n",
       " [0.99389112],\n",
       " [0.99473488],\n",
       " [0.99548191],\n",
       " [0.99613237],\n",
       " [0.9966861],\n",
       " [0.99714315],\n",
       " [0.9975034],\n",
       " [0.99776685],\n",
       " [0.99793357],\n",
       " [0.99800336],\n",
       " [0.99797654],\n",
       " [0.99785274],\n",
       " [0.99763191],\n",
       " [0.99731445],\n",
       " [0.9968999],\n",
       " [0.99638832],\n",
       " [0.99577993],\n",
       " [0.99507451],\n",
       " [0.99427211],\n",
       " [0.99337268],\n",
       " [0.99237633],\n",
       " [0.99128306],\n",
       " [0.99009293],\n",
       " [0.98880577],\n",
       " [0.98742163],\n",
       " [0.98594064],\n",
       " [0.98436278],\n",
       " [0.98268819],\n",
       " [0.98091674],\n",
       " [0.97904849],\n",
       " [0.97708368],\n",
       " [0.9750216],\n",
       " [0.97286296],\n",
       " [0.97060782],\n",
       " [0.96825624],\n",
       " [0.96580833],\n",
       " [0.96326429],\n",
       " [0.96062428],\n",
       " [0.95788813],\n",
       " [0.95505607],\n",
       " [0.95212817],\n",
       " [0.94910425],\n",
       " [0.9459846],\n",
       " [0.94276953],\n",
       " [0.93945879],\n",
       " [0.93605316],\n",
       " [0.93255222],\n",
       " [0.92895651],\n",
       " [0.92526615],\n",
       " [0.92148107],\n",
       " [0.91760176],\n",
       " [0.91362828],\n",
       " [0.90956098],\n",
       " [0.90540004],\n",
       " [0.90114564],\n",
       " [0.89679807],\n",
       " [0.89235771],\n",
       " [0.88782471],\n",
       " [0.88319957],\n",
       " [0.87848228],\n",
       " [0.87367344],\n",
       " [0.86877328],\n",
       " [0.86378068],\n",
       " [0.85869789],\n",
       " [0.85352474],\n",
       " [0.84826231],\n",
       " [0.84291071],\n",
       " [0.83747059],\n",
       " [0.8319422],\n",
       " [0.82632589],\n",
       " [0.82062227],\n",
       " [0.81483179],\n",
       " [0.8089543],\n",
       " [0.80299067],\n",
       " [0.79694182],\n",
       " [0.79080808],\n",
       " [0.78458995],\n",
       " [0.77828836],\n",
       " [0.77190363],\n",
       " [0.76543641],\n",
       " [0.75888759],\n",
       " [0.75225776],\n",
       " [0.74554753],\n",
       " [0.73875761],\n",
       " [0.73188895],\n",
       " [0.72494185],\n",
       " [0.71791768],\n",
       " [0.71081662],\n",
       " [0.70363986],\n",
       " [0.69638824],\n",
       " [0.68906242],\n",
       " [0.68166327],\n",
       " [0.67419171],\n",
       " [0.66664648],\n",
       " [0.65903097],\n",
       " [0.65134585],\n",
       " [0.6435923],\n",
       " [0.63577145],\n",
       " [0.62788409],\n",
       " [0.61993176],\n",
       " [0.61191463],\n",
       " [0.60383373],\n",
       " [0.59569013],\n",
       " [0.58748394],\n",
       " [0.5792169],\n",
       " [0.57089001],\n",
       " [0.56250465],\n",
       " [0.55406147],\n",
       " [0.54556185],\n",
       " [0.53700674],\n",
       " [0.52839732],\n",
       " [0.51973462],\n",
       " [0.51101983],\n",
       " [0.50225401],\n",
       " [0.49343818],\n",
       " [0.4845736],\n",
       " [0.47566146],\n",
       " [0.4667027],\n",
       " [0.45769858],\n",
       " [0.44865018],\n",
       " [0.43955863],\n",
       " [0.43042511],\n",
       " [0.42125076],\n",
       " [0.41203654],\n",
       " [0.40278381],\n",
       " [0.39349073],\n",
       " [0.38416189],\n",
       " [0.37479794],\n",
       " [0.36540037],\n",
       " [0.35597026],\n",
       " [0.34650904],\n",
       " [0.33701801],\n",
       " [0.32749736],\n",
       " [0.3179481],\n",
       " [0.30837154],\n",
       " [0.29876748],\n",
       " [0.28913796],\n",
       " [0.27948403],\n",
       " [0.2698068],\n",
       " [0.26010728],\n",
       " [0.25038648],\n",
       " [0.24064535],\n",
       " [0.23088503],\n",
       " [0.22110641],\n",
       " [0.21131052],\n",
       " [0.20149831],\n",
       " [0.19167078],\n",
       " [0.18182884],\n",
       " [0.17197344],\n",
       " [0.16210556],\n",
       " [0.15222608],\n",
       " [0.14233595],\n",
       " [0.13243602],\n",
       " [0.12252726],\n",
       " [0.1126105],\n",
       " [0.10268664],\n",
       " [0.092753157],\n",
       " [0.082815289],\n",
       " [0.072873205],\n",
       " [0.062927768],\n",
       " [0.052980103],\n",
       " [0.043031361],\n",
       " [0.033082664],\n",
       " [0.02313352],\n",
       " [0.013185039],\n",
       " [0.0032379776],\n",
       " [-0.0067080334],\n",
       " [-0.016651101],\n",
       " [-0.026590452],\n",
       " [-0.036525257]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "989\n",
      "989\n"
     ]
    }
   ],
   "source": [
    "print len(test_y)\n",
    "print len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
