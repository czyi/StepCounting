{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyi/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "num_input = 6\n",
    "timesteps = 50 # timesteps\n",
    "num_hidden = 100 # hidden layer num of features\n",
    "num_output= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_sensor(filename):\n",
    "    with open(filename, \"r\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        dataset = [row[17:23] for row in reader]\n",
    "        #data_x\n",
    "        return np.array(dataset)\n",
    "    \n",
    "def read_xml(filename, length):\n",
    "    f = open(filename)\n",
    "    cts = f.read()\n",
    "    f.close()\n",
    "\n",
    "    p_foot = re.compile(r'<WhichFoot>(.*?)</WhichFoot>')\n",
    "    all_foot = p_foot.findall(cts)\n",
    "\n",
    "    p_time = re.compile(r'<Time>(.*?)</Time>')\n",
    "    all_time = p_time.findall(cts)\n",
    "\n",
    "    strike_times = []\n",
    "    #L-1 R-0\n",
    "    strike_times.append([0.0, 0.5])\n",
    "    for i in range(len(all_foot)):\n",
    "        if(all_foot[i]=='L'):\n",
    "            strike_times.append([float(all_time[i]), 1])\n",
    "        else:\n",
    "            strike_times.append([float(all_time[i]), 0])\n",
    "    strike_times[-1][1] = 0.5\n",
    "    strike_times.append([length/25.0, 0.5])\n",
    "\n",
    "    window_y = []\n",
    "    strike_index=0\n",
    "    for i in range(length):\n",
    "        if(i/25.0 >= strike_times[strike_index+1][0]):\n",
    "            strike_index += 1\n",
    "        window_y.append([strike_times[strike_index][1]])\n",
    "\n",
    "    p_info = re.compile(r'<StartTime>(.*?)</StartTime>\\n\\t<EndTime>(.*?)</EndTime>\\n\\t<NSteps>(.*?)</NSteps>\\n\\t<Direction>(.*?)</Direction>')\n",
    "    all_info = p_info.findall(cts)#start_time, end_time, step_num, direction=turn\n",
    "\n",
    "    for i in range(len(all_info)):\n",
    "        if(all_info[i][3][:4]=='Turn'):\n",
    "#             print(all_info[i])\n",
    "            start_time = int(float(all_info[i][0])*25)\n",
    "            end_time = int(float(all_info[i][1])*25)\n",
    "#             print('start and end time : ', all_info[i][0], all_info[i][1])\n",
    "            for t in range(start_time-1, end_time):\n",
    "                window_y[t] = [0.5]\n",
    "\n",
    "    p_feature = re.compile(r'<Feature>\\n\\t\\t\\t<StartTime>(.*?)</StartTime>\\n\\t\\t\\t<EndTime>(.*?)</EndTime>')\n",
    "    all_feature = p_feature.findall(cts)#start_time, end_time, step_num, direction=turn\n",
    "    \n",
    "#     print(filename, length)\n",
    "    for i in range(len(all_feature)):\n",
    "        start_time = int(float(all_feature[i][0])*25)\n",
    "        end_time = int(float(all_feature[i][1])*25)\n",
    "#         print(start_time-1, end_time)\n",
    "        if(end_time<=length):\n",
    "            for t in range(start_time-1, end_time):\n",
    "                window_y[t] = [0.5]\n",
    "            \n",
    "#     print(len(window_y))  \n",
    "    return window_y\n",
    "\n",
    "def add_data(path, person, phone_location, assistant):\n",
    "    data_x = read_sensor('weallwalk/sensor/iPhoneSensors_T'+str(path)+'_ID'+str(person)+'_'+phone_location+'_'+assistant+'.csv')\n",
    "    data_y = read_xml('weallwalk/xml/T'+str(path)+'_ID'+str(person)+'_'+assistant+'.xml', len(data_x))\n",
    "    \n",
    "    split_x, split_x_part = [], []\n",
    "    split_y, split_y_part = [], []\n",
    "    for i in range(len(data_y)):\n",
    "        if(data_y[i][0]!=0.5):\n",
    "            split_y_part.append(data_y[i])\n",
    "            split_x_part.append(data_x[i])\n",
    "        else:\n",
    "            if(len(split_y_part)>0):\n",
    "                split_y.append(split_y_part)\n",
    "                split_x.append(split_x_part)\n",
    "                split_y_part = []\n",
    "                split_x_part = []\n",
    "    \n",
    "    data_x_seq, data_y_seq = [], []\n",
    "    for i in range(len(split_x)):\n",
    "        data_x_part, data_y_part = [], []\n",
    "        for j in range(len(split_x[i])-timesteps):\n",
    "            x = split_x[i][j:j+timesteps]\n",
    "            y = split_y[i][j:j+timesteps]\n",
    "            data_x_part.append(x)\n",
    "            data_y_part.append(y)\n",
    "        if(len(data_x_part)>0):\n",
    "            data_x_seq.append(data_x_part)\n",
    "            data_y_seq.append(data_y_part)\n",
    "    \n",
    "    return data_x_seq, data_y_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, '1L', 'GD'], [1, 1, '2R', 'GD'], [1, 4, '1L', 'GD'], [1, 4, '2R', 'GD'], [1, 8, '1L', 'GD'], [1, 8, '2R', 'GD'], [2, 1, '1L', 'GD'], [2, 1, '2R', 'GD'], [2, 4, '1L', 'GD'], [2, 4, '2R', 'GD'], [2, 8, '1L', 'GD'], [2, 8, '2R', 'GD'], [3, 1, '1L', 'GD'], [3, 1, '2R', 'GD'], [3, 4, '1L', 'GD'], [3, 4, '2R', 'GD'], [3, 8, '1L', 'GD'], [3, 8, '2R', 'GD'], [4, 1, '1L', 'GD'], [4, 1, '2R', 'GD'], [4, 4, '1L', 'GD'], [4, 4, '2R', 'GD'], [4, 8, '1L', 'GD'], [4, 8, '2R', 'GD']]\n"
     ]
    }
   ],
   "source": [
    "step_data_list = []\n",
    "for i in range(1,5):\n",
    "    step_data_list.append([i, 1, '1L', 'GD'])\n",
    "    step_data_list.append([i, 1, '2R', 'GD'])\n",
    "    step_data_list.append([i, 4, '1L', 'GD'])\n",
    "    step_data_list.append([i, 4, '2R', 'GD'])\n",
    "    step_data_list.append([i, 8, '1L', 'GD'])\n",
    "    step_data_list.append([i, 8, '2R', 'GD'])\n",
    "    \n",
    "print(step_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50526\n",
      "50526\n"
     ]
    }
   ],
   "source": [
    "data_x, data_y = [], []\n",
    "for i in step_data_list:\n",
    "    data_x_segement, data_y_segement = add_data(i[0], i[1], i[2], i[3])\n",
    "    for dx in data_x_segement:\n",
    "        data_x.extend(dx)\n",
    "    for dy in data_y_segement:\n",
    "        data_y.extend(dy)\n",
    "    \n",
    "print(len(data_x))\n",
    "print(len(data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50526\n"
     ]
    }
   ],
   "source": [
    "order = list(range(0,len(data_x),1))\n",
    "random.shuffle(order)\n",
    "\n",
    "train_x = [data_x[i] for i in order]\n",
    "train_y = [data_y[i] for i in order]\n",
    "\n",
    "print(len(train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 1, '1L', 'GD'], [5, 1, '2R', 'GD'], [5, 4, '1L', 'GD'], [5, 4, '2R', 'GD'], [5, 8, '1L', 'GD'], [5, 8, '2R', 'GD']]\n"
     ]
    }
   ],
   "source": [
    "step_valid_list = []   \n",
    "\n",
    "for i in range(5,6):\n",
    "    step_valid_list.append([i, 1, '1L', 'GD'])\n",
    "    step_valid_list.append([i, 1, '2R', 'GD'])\n",
    "    step_valid_list.append([i, 4, '1L', 'GD'])\n",
    "    step_valid_list.append([i, 4, '2R', 'GD'])\n",
    "    step_valid_list.append([i, 8, '1L', 'GD'])\n",
    "    step_valid_list.append([i, 8, '2R', 'GD'])\n",
    "      \n",
    "print(step_valid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "44\n",
      "[16, 444, 678, 327, 412, 304, 1500, 16, 444, 678, 327, 412, 304, 1500, 16, 320, 389, 62, 217, 284, 124, 1055, 16, 320, 389, 62, 217, 284, 124, 1055, 14, 354, 571, 266, 339, 265, 970, 14, 354, 571, 266, 339, 265, 970]\n"
     ]
    }
   ],
   "source": [
    "valid_x, valid_y=[], []\n",
    "for i in step_valid_list:\n",
    "    data_x_segement, data_y_segement = add_data(i[0], i[1], i[2], i[3])\n",
    "    valid_x.extend(data_x_segement)\n",
    "    valid_y.extend(data_y_segement)\n",
    "#     test_x.append(data_x_segement)\n",
    "#     test_y.append(data_y_segement)\n",
    "    \n",
    "print(len(valid_x))\n",
    "print(len(valid_y))\n",
    "\n",
    "print([len(i) for i in valid_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 1, '1L', 'GD'], [6, 1, '2R', 'GD'], [6, 4, '1L', 'GD'], [6, 4, '2R', 'GD'], [6, 8, '1L', 'GD'], [6, 8, '2R', 'GD']]\n"
     ]
    }
   ],
   "source": [
    "step_test_list = []   \n",
    "\n",
    "for i in range(6,7):\n",
    "    step_test_list.append([i, 1, '1L', 'GD'])\n",
    "    step_test_list.append([i, 1, '2R', 'GD'])\n",
    "    step_test_list.append([i, 4, '1L', 'GD'])\n",
    "    step_test_list.append([i, 4, '2R', 'GD'])\n",
    "    step_test_list.append([i, 8, '1L', 'GD'])\n",
    "    step_test_list.append([i, 8, '2R', 'GD'])\n",
    "      \n",
    "print(step_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "[217, 204, 1235, 83, 217, 204, 1235, 83, 448, 810, 20, 448, 810, 20, 481, 949, 15, 481, 949, 15]\n"
     ]
    }
   ],
   "source": [
    "test_x, test_y=[], []\n",
    "for i in step_test_list:\n",
    "    data_x_segement, data_y_segement = add_data(i[0], i[1], i[2], i[3])\n",
    "    test_x.extend(data_x_segement)\n",
    "    test_y.extend(data_y_segement)\n",
    "#     test_x.append(data_x_segement)\n",
    "#     test_y.append(data_y_segement)\n",
    "    \n",
    "print(len(test_x))\n",
    "print(len(test_y))\n",
    "\n",
    "print([len(i) for i in test_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 50, 1)\n",
      "(50, 1)\n"
     ]
    }
   ],
   "source": [
    "NUM_LAYERS=2\n",
    "\n",
    "def LstmCell():\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_hidden)#, forget_bias=1.0)\n",
    "    cell = tf.contrib.rnn.DropoutWrapper(lstm_cell, output_keep_prob=0.5)\n",
    "    return cell\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default(), tf.device('/gpu:0'):\n",
    "    # tf Graph input\n",
    "    X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "    Y = tf.placeholder(\"float\", [None, timesteps, num_output])\n",
    "    \n",
    "    # Define weights\n",
    "    weights = {\n",
    "        'out': tf.Variable(tf.random_normal([num_hidden, num_output]))\n",
    "    }\n",
    "    biases = {\n",
    "        'out': tf.Variable(tf.random_normal([num_output]))\n",
    "    }\n",
    "    \n",
    "    def RNN(x, weights, biases):\n",
    "        x = tf.unstack(x, timesteps, 1)\n",
    "        cell = tf.contrib.rnn.MultiRNNCell([LstmCell() for _ in range(NUM_LAYERS)])\n",
    "        outputs, state = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "        outputs = tf.transpose(outputs, [1,0,2])\n",
    "\n",
    "#         return tf.matmul(outputs[-2], weights['out']) + biases['out']\n",
    "        ret = []\n",
    "#         print(outputs.shape)\n",
    "        for i in range(0, timesteps):\n",
    "            ret.append(tf.matmul(outputs[i], weights['out']) + biases['out'])\n",
    "            \n",
    "        return ret\n",
    "\n",
    "#         return np.array(ret)\n",
    "    \n",
    "    logits = RNN(X, weights, biases)\n",
    "    logits = tf.transpose(logits, [1,0,2])\n",
    "#     print(len(logits))\n",
    "    print(logits.shape)\n",
    "    print(logits[0].shape)\n",
    "    mean_train = tf.reduce_mean(X)\n",
    "    \n",
    "    \n",
    "    loss = tf.reduce_mean(tf.squared_difference(logits, Y))\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss)\n",
    "    \n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50526\n",
      "50526\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "batch_start = 0;\n",
    "train_length = len(train_x)\n",
    "print(train_length)\n",
    "\n",
    "train_x_extend = [i for i in train_x]\n",
    "train_y_extend = [i for i in train_y]\n",
    "\n",
    "print(len(train_x_extend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50782\n"
     ]
    }
   ],
   "source": [
    "if(len(train_x_extend)==len(train_x)):\n",
    "    train_x_extend.extend(train_x[0:batch_size])\n",
    "    train_y_extend.extend(train_y[0:batch_size])\n",
    "print(len(train_x_extend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_accuarcy(y, _y):\n",
    "#     print(len(y))\n",
    "#     print(len(y[0]))\n",
    "#     print(len(y[0][0]))\n",
    "#     print(y[0][0])\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i in range(len(y[0])):\n",
    "        total += 1\n",
    "        if(y[0][i][0] == round(_y[0][i][0])):\n",
    "            count += 1\n",
    "    for i in range(1, len(y)):\n",
    "        total += 1\n",
    "        if(y[i][-1][0] == round(_y[i][-1][0])):\n",
    "            count += 1;\n",
    "    return(count*1.0/total)\n",
    "#     print(\"train accuarcy : \", count/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 0.429875, train accuarcy : 0.449180\n",
      "Loss at step 200: 0.120769, train accuarcy : 0.875410\n",
      "Loss at step 400: 0.100113, train accuarcy : 0.911475\n",
      "Loss at step 600: 0.079659, train accuarcy : 0.901639\n",
      "Loss at step 800: 0.073024, train accuarcy : 0.911475\n",
      "Loss at step 1000: 0.067183, train accuarcy : 0.918033\n",
      "Loss at step 1200: 0.068893, train accuarcy : 0.931148\n",
      "Loss at step 1400: 0.065733, train accuarcy : 0.950820\n",
      "Loss at step 1600: 0.059491, train accuarcy : 0.954098\n",
      "Loss at step 1800: 0.064077, train accuarcy : 0.940984\n",
      "Loss at step 2000: 0.059863, train accuarcy : 0.944262\n",
      "Loss at step 2200: 0.060927, train accuarcy : 0.944262\n",
      "Loss at step 2400: 0.053983, train accuarcy : 0.944262\n",
      "Loss at step 2600: 0.054054, train accuarcy : 0.954098\n",
      "Loss at step 2800: 0.050286, train accuarcy : 0.973770\n",
      "Loss at step 3000: 0.056035, train accuarcy : 0.957377\n"
     ]
    }
   ],
   "source": [
    "training_steps = 3001\n",
    "\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "# config.gpu_options.allocator_type = 'BFC'\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.40\n",
    "with tf.Session(graph=graph, config=config) as session:\n",
    "#     saver.restore(session, tf.train.latest_checkpoint('lstm_check'))\n",
    "#     saver.restore(session, \"lstm_check/my-model-gpu-error-metric-dropout2-gd.ckpt-5000\")\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    for step in range(training_steps):      \n",
    "        feed_dict = {X: train_x[batch_start:batch_start+batch_size], Y: train_y[batch_start:batch_start+batch_size]}\n",
    "        _, l, predictions, m = session.run([optimizer, loss, logits, mean_train], feed_dict = feed_dict)\n",
    "        if (step % 200 == 0):\n",
    "            train_accuarcy = cal_accuarcy(train_y[batch_start:batch_start+batch_size], predictions)\n",
    "            print('Loss at step %d: %f, train accuarcy : %f' % (step, l, train_accuarcy))\n",
    "            #train accuarcy\n",
    "        if (step % 1000 == 0):\n",
    "            saver.save(session, 'lstm_check/my-model-gpu-error-metric-dropout2-gd.ckpt', global_step=step)\n",
    "        batch_start += batch_size\n",
    "        if(batch_start>=train_length):\n",
    "            batch_start -=train_length\n",
    "#     train_loss, train_logits = session.run([loss,logits], feed_dict={X: train_x, Y: train_y})\n",
    "#     test_loss, test_logits = session.run([loss,logits], feed_dict={X: test_x, Y: test_y})\n",
    "    test_loss, test_logits = [], []\n",
    "    for i in range(len(test_x)):\n",
    "#         saver.restore(session, tf.train.latest_checkpoint('lstm_check'))\n",
    "        test_loss_part, test_logits_part = session.run([loss,logits], feed_dict={X: test_x[i], Y: test_y[i]})\n",
    "        test_loss.append(test_loss_part)\n",
    "        test_logits.append(test_logits_part)\n",
    "        \n",
    "    valid_loss, valid_logits = [], []\n",
    "    for i in range(len(valid_x)):\n",
    "#         saver.restore(session, tf.train.latest_checkpoint('lstm_check'))\n",
    "        valid_loss_part, valid_logits_part = session.run([loss,logits], feed_dict={X: valid_x[i], Y: valid_y[i]})\n",
    "        valid_loss.append(valid_loss_part)\n",
    "        valid_logits.append(valid_logits_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "16\n",
      "50\n",
      "14864\n",
      "20010\n",
      "valid accuarcy :  0.7428285857071464\n"
     ]
    }
   ],
   "source": [
    "print(len(valid_logits))\n",
    "print(len(valid_logits[0]))\n",
    "print(len(valid_logits[0][0]))  \n",
    "\n",
    "valid_y_seq_list, valid_logits_bin_list = [], []\n",
    "\n",
    "for t in valid_logits:  \n",
    "    t_all = [i for i in t[0]]\n",
    "    t_all.extend([i[-1] for i in t[1:]])\n",
    "#     print(len(t_all)-len(t))\n",
    "    \n",
    "    valid_logits_part = [[round(i[0])] for i in t_all]\n",
    "    for i in range(1, len(valid_logits_part)-1):\n",
    "        if(valid_logits_part[i-1][0]!=valid_logits_part[i][0] and valid_logits_part[i-1][0]==valid_logits_part[i+1][0]):\n",
    "            valid_logits_part[i][0]=valid_logits_part[i-1][0]   \n",
    "    valid_logits_bin_list.append(valid_logits_part)\n",
    "\n",
    "    \n",
    "for t in valid_y:  \n",
    "    t_all = [i for i in t[0]]\n",
    "    t_all.extend([i[-1] for i in t[1:]])\n",
    "    valid_y_seq_list.append(t_all)\n",
    "\n",
    "# print(valid_y_seq_list)\n",
    "    \n",
    "count = 0\n",
    "total = 0\n",
    "# print(len(valid_y_seq_list), len(valid_y), len(valid_logits_bin_list), len(valid_logits))\n",
    "for i in range(0, len(valid_y_seq_list)):\n",
    "    total += len(valid_y_seq_list[i])\n",
    "#     print(len(valid_y_seq_list[i]), len(valid_logits_bin_list[i]))\n",
    "    for j in range(0, len(valid_y_seq_list[i])):\n",
    "        if(valid_y_seq_list[i][j][0] == valid_logits_bin_list[i][j][0]):\n",
    "            count += 1\n",
    "\n",
    "print(count)\n",
    "print(total)\n",
    "print(\"valid accuarcy : \", count*1.0/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step number for each segement\n",
      "[4, 41, 61, 31, 39, 30, 125, 4, 41, 61, 31, 39, 30, 125, 4, 30, 36, 9, 18, 29, 16, 91, 4, 30, 36, 9, 18, 29, 16, 91, 5, 32, 49, 24, 30, 24, 78, 5, 32, 49, 24, 30, 24, 78]\n",
      "[5, 34, 67, 26, 39, 32, 131, 8, 40, 62, 30, 40, 31, 113, 7, 31, 37, 10, 22, 28, 16, 93, 5, 31, 36, 10, 20, 28, 16, 95, 4, 32, 48, 23, 30, 24, 79, 4, 32, 49, 23, 30, 24, 78]\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "step_time_actual, step_time_predict= [], []\n",
    "step_time_actual_gap = []\n",
    "\n",
    "#valid_y_seq_list, valid_logits_bin_list\n",
    "for i in range(0, len(valid_y_seq_list)):\n",
    "    step_time_actual_part, step_time_predict_part= [], []\n",
    "    for j in range(1, len(valid_y_seq_list[i])):\n",
    "        if(abs(valid_y_seq_list[i][j][0]-valid_y_seq_list[i][j-1][0])>0.5):\n",
    "            step_time_actual_part.append(j)\n",
    "    #     if(abs(valid_logits[i][0]-valid_logits[i-1][0])>0.5):\n",
    "        if(abs(valid_logits_bin_list[i][j][0]-valid_logits_bin_list[i][j-1][0])>0.5):\n",
    "            step_time_predict_part.append(j)\n",
    "    step_time_actual.append(step_time_actual_part)\n",
    "    \n",
    "    average_time = (step_time_predict_part[-1]-step_time_predict_part[0])/(len(step_time_predict_part)-1)\n",
    "    step_time_predict_part_1 = [step_time_predict_part[0]]\n",
    "#     for i in range(1, len(step_time_predict_part)):\n",
    "#         if(step_time_predict_part[i]-step_time_predict_part_1[-1]>average_time/2):\n",
    "#             step_time_predict_part_1.append(step_time_predict_part[i])\n",
    "    j = 1\n",
    "    while j<len(step_time_predict_part):\n",
    "        if(step_time_predict_part[j]-step_time_predict_part_1[-1]>average_time/4):\n",
    "            step_time_predict_part_1.append(step_time_predict_part[j])\n",
    "            j += 1\n",
    "        else:\n",
    "            j += 2\n",
    "            \n",
    "#     print(step_time_predict_part)\n",
    "#     print(step_time_predict_part_1) \n",
    "    \n",
    "    step_time_predict.append(step_time_predict_part_1)\n",
    "    \n",
    "    step_time_actual_gap_part = []\n",
    "    step_time_actual_gap_part.append(0)\n",
    "#     step_time_actual_gap_part.append(step_time_actual_part[0]/2.0)\n",
    "    for i in range(1, len(step_time_actual_part)):\n",
    "        step_time_actual_gap_part.append((step_time_actual_part[i-1]+step_time_actual_part[i])/2.0)\n",
    "    step_time_actual_gap_part.append(step_time_actual_part[-1]*2)\n",
    "    step_time_actual_gap.append(step_time_actual_gap_part)\n",
    "\n",
    "print('Step number for each segement')\n",
    "print([len(i) for i in step_time_actual])   \n",
    "print([len(i) for i in step_time_predict])\n",
    "\n",
    "print('======')\n",
    "iii = 13\n",
    "# print(step_time_actual[iii])\n",
    "# print(step_time_actual_gap[iii])\n",
    "# print(step_time_predict[iii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "44\n",
      "97\n",
      "[1, 0, 7, 0, 2, 2, 24, 4, 4, 11, 3, 6, 4, 3, 3, 2, 1, 1, 4, 0, 0, 3, 1, 2, 0, 1, 2, 0, 0, 4, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]\n",
      "44\n",
      "44\n",
      "[1, 0, 6, 0, 0, 2, 6, 4, 0, 1, 0, 1, 1, 0, 3, 1, 1, 1, 4, 0, 0, 2, 1, 1, 0, 1, 2, 0, 0, 4, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "error : \n",
      "total undercount metric 1:\t 0.2512406947890819\n",
      "total overcount metric 1:\t 0.23014888337468983\n",
      "total undercount metric 2:\t 0.05334987593052109\n",
      "total overcount metric 2:\t 0.06017369727047146\n",
      "total undercount metric 3:\t 0.020471464019851116\n",
      "total overcount metric 3:\t 0.02729528535980149\n"
     ]
    }
   ],
   "source": [
    "total_step_count = sum([len(i) for i in step_time_actual])\n",
    "metric1_undercount = 0\n",
    "metric2_undercount = 0\n",
    "metric3_undercount = 0\n",
    "metric1_overcount = 0\n",
    "metric2_overcount = 0\n",
    "metric3_overcount = 0\n",
    "\n",
    "metric2_overcount_list = []\n",
    "metric3_overcount_list = []\n",
    "\n",
    "print(len(valid_x))\n",
    "\n",
    "for i in range(len(valid_x)):\n",
    "    step_count = len(step_time_actual[i])\n",
    "    undercount = 0\n",
    "    overcount = 0\n",
    "\n",
    "    for j in range(1, step_count):\n",
    "        gap_count = [t for t in step_time_predict[i] if t>=step_time_actual[i][j-1] and t<step_time_actual[i][j]]\n",
    "    #     print(gap_count)\n",
    "        if(len(gap_count)>1):\n",
    "            overcount += len(gap_count)-1\n",
    "        if(len(gap_count)<1):\n",
    "            undercount += 1\n",
    "    gap_count = [t for t in step_time_predict[i] if t>=step_time_actual[i][-1]]\n",
    "    if(len(gap_count)>1):\n",
    "        overcount += len(gap_count)-1\n",
    "    if(len(gap_count)<1):\n",
    "        undercount += 1\n",
    "    \n",
    "    metric1_undercount += undercount\n",
    "    metric1_overcount += overcount\n",
    "    \n",
    "    undercount = 0\n",
    "    overcount = 0\n",
    "    for j in range(1, len(step_time_actual_gap[i])):\n",
    "        gap_count = [t for t in step_time_predict[i] if t>=step_time_actual_gap[i][j-1] and t<step_time_actual_gap[i][j]]\n",
    "    #     print(gap_count)\n",
    "        if(len(gap_count)>1):\n",
    "            overcount += (len(gap_count)-1)\n",
    "        if(len(gap_count)<1):\n",
    "            undercount += 1    \n",
    "    \n",
    "    metric2_undercount += undercount\n",
    "    metric2_overcount += overcount  \n",
    "    metric2_overcount_list.append(overcount)\n",
    "    \n",
    "#     print(undercount, overcount)\n",
    "#     print('undercount : ', undercount*1.0/step_count)\n",
    "#     print('overcount : ', overcount*1.0/step_count)\n",
    "    diff = len(step_time_predict[i])-len(step_time_actual[i])\n",
    "#     if(diff==0):\n",
    "#         print(\"segement correct!\")\n",
    "\n",
    "    if(diff<0):\n",
    "#         print('segement undercount : ', 1-len(step_time_predict[i])*1.0/len(step_time_actual[i]))\n",
    "        metric3_undercount -= diff\n",
    "        metric3_overcount_list.append(0)\n",
    "#     if(diff>=0):\n",
    "    else:\n",
    "#         print('segement overcount : ', 1-len(step_time_actual[i])*1.0/len(step_time_predict[i]))\n",
    "        metric3_overcount += diff\n",
    "        metric3_overcount_list.append(diff)\n",
    "\n",
    "print(len(metric2_overcount_list))\n",
    "print(sum(metric2_overcount_list))\n",
    "print(metric2_overcount_list)\n",
    "print(len(metric3_overcount_list))\n",
    "print(sum(metric3_overcount_list))\n",
    "print(metric3_overcount_list)\n",
    "        \n",
    "print('error : ')\n",
    "print(\"total undercount metric 1:\\t\", metric1_undercount*1.0/total_step_count)\n",
    "print(\"total overcount metric 1:\\t\", metric1_overcount*1.0/total_step_count)\n",
    "print(\"total undercount metric 2:\\t\", metric2_undercount*1.0/total_step_count)\n",
    "print(\"total overcount metric 2:\\t\", metric2_overcount*1.0/total_step_count)\n",
    "print(\"total undercount metric 3:\\t\", metric3_undercount*1.0/total_step_count)\n",
    "print(\"total overcount metric 3:\\t\", metric3_overcount*1.0/total_step_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss :  [0.53710496, 0.49201339, 0.48864323, 0.50488245, 0.12102283, 0.10364111, 0.14515381, 0.15539099, 0.069909267, 0.059540894, 0.078309357, 0.060364924, 0.054533385, 0.15362091, 0.091440327, 0.094737224, 0.066873126, 0.082732052, 0.087513648, 0.069516987]\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss : \", test_loss)\n",
    "print(len(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "217\n",
      "50\n",
      "7681\n",
      "9904\n",
      "test accuarcy :  0.7755452342487884\n"
     ]
    }
   ],
   "source": [
    "print(len(test_logits))\n",
    "print(len(test_logits[0]))\n",
    "print(len(test_logits[0][0]))  \n",
    "\n",
    "test_y_seq_list, test_logits_bin_list = [], []\n",
    "\n",
    "for t in test_logits:  \n",
    "    t_all = [i for i in t[0]]\n",
    "    t_all.extend([i[-1] for i in t[1:]])\n",
    "#     print(len(t_all)-len(t))\n",
    "    \n",
    "    test_logits_part = [[round(i[0])] for i in t_all]\n",
    "    for i in range(1, len(test_logits_part)-1):\n",
    "        if(test_logits_part[i-1][0]!=test_logits_part[i][0] and test_logits_part[i-1][0]==test_logits_part[i+1][0]):\n",
    "            test_logits_part[i][0]=test_logits_part[i-1][0]   \n",
    "    test_logits_bin_list.append(test_logits_part)\n",
    "    \n",
    "    \n",
    "#     test_logits_part_one = [i[0] for i in test_logits_part]\n",
    "#     test_logits_part_time = [i for i in range(1, len(test_logits_part)) if test_logits_part[i-1]!=test_logits_part[i]]\n",
    "#     print(test_logits_part_one)\n",
    "#     print(test_logits_part_time)\n",
    "#     average_time = (test_logits_part_time[-1]-test_logits_part_time[0])/(len(test_logits_part_time)-1)\n",
    "#     print(average_time)\n",
    "    \n",
    "#     test_logits_part_one_remove = []\n",
    "    \n",
    "#     for i in range(1, len(test_logits_part_time)):\n",
    "#         if(test_logits_part_time[i]-test_logits_part_time[i-1]<average_time/2):\n",
    "#             for j in range(test_logits_part_time[i], test_logits_part_time[i-1]):\n",
    "#                 test_logits_part_one[j]=\n",
    "        \n",
    "    \n",
    "#     test_logits_bin_list.append([[i] for i in test_logits_part_one])\n",
    "    \n",
    "for t in test_y:  \n",
    "    t_all = [i for i in t[0]]\n",
    "    t_all.extend([i[-1] for i in t[1:]])\n",
    "    test_y_seq_list.append(t_all)\n",
    "\n",
    "# print(test_y_seq_list)\n",
    "    \n",
    "count = 0\n",
    "total = 0\n",
    "for i in range(0, len(test_y_seq_list)):\n",
    "    total += len(test_y_seq_list[i])\n",
    "    for j in range(0, len(test_y_seq_list[i])):\n",
    "        if(test_y_seq_list[i][j][0] == test_logits_bin_list[i][j][0]):\n",
    "            count += 1\n",
    "\n",
    "print(count)\n",
    "print(total)\n",
    "print(\"test accuarcy : \", count*1.0/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step number for each segement\n",
      "[22, 20, 105, 10, 22, 20, 105, 10, 44, 76, 5, 44, 76, 5, 42, 78, 4, 42, 78, 4]\n",
      "[26, 26, 113, 12, 21, 21, 95, 10, 44, 77, 5, 44, 75, 5, 42, 78, 4, 42, 78, 5]\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "step_time_actual, step_time_predict= [], []\n",
    "step_time_actual_gap = []\n",
    "\n",
    "#test_y_seq_list, test_logits_bin_list\n",
    "for i in range(0, len(test_y_seq_list)):\n",
    "    step_time_actual_part, step_time_predict_part= [], []\n",
    "    for j in range(1, len(test_y_seq_list[i])):\n",
    "        if(abs(test_y_seq_list[i][j][0]-test_y_seq_list[i][j-1][0])>0.5):\n",
    "            step_time_actual_part.append(j)\n",
    "    #     if(abs(test_logits[i][0]-test_logits[i-1][0])>0.5):\n",
    "        if(abs(test_logits_bin_list[i][j][0]-test_logits_bin_list[i][j-1][0])>0.5):\n",
    "            step_time_predict_part.append(j)\n",
    "    step_time_actual.append(step_time_actual_part)\n",
    "    \n",
    "    average_time = (step_time_predict_part[-1]-step_time_predict_part[0])/(len(step_time_predict_part)-1)\n",
    "    step_time_predict_part_1 = [step_time_predict_part[0]]\n",
    "#     for i in range(1, len(step_time_predict_part)):\n",
    "#         if(step_time_predict_part[i]-step_time_predict_part_1[-1]>average_time/2):\n",
    "#             step_time_predict_part_1.append(step_time_predict_part[i])\n",
    "    j = 1\n",
    "    while j<len(step_time_predict_part):\n",
    "        if(step_time_predict_part[j]-step_time_predict_part_1[-1]>average_time/4):\n",
    "            step_time_predict_part_1.append(step_time_predict_part[j])\n",
    "            j += 1\n",
    "        else:\n",
    "            j += 2\n",
    "            \n",
    "#     print(step_time_predict_part)\n",
    "#     print(step_time_predict_part_1) \n",
    "    \n",
    "    step_time_predict.append(step_time_predict_part_1)\n",
    "    \n",
    "    step_time_actual_gap_part = []\n",
    "    step_time_actual_gap_part.append(0)\n",
    "#     step_time_actual_gap_part.append(step_time_actual_part[0]/2.0)\n",
    "    for i in range(1, len(step_time_actual_part)):\n",
    "        step_time_actual_gap_part.append((step_time_actual_part[i-1]+step_time_actual_part[i])/2.0)\n",
    "    step_time_actual_gap_part.append(step_time_actual_part[-1]*2)\n",
    "    step_time_actual_gap.append(step_time_actual_gap_part)\n",
    "\n",
    "print('Step number for each segement')\n",
    "print([len(i) for i in step_time_actual])   \n",
    "print([len(i) for i in step_time_predict])\n",
    "\n",
    "print('======')\n",
    "iii = 13\n",
    "# print(step_time_actual[iii])\n",
    "# print(step_time_actual_gap[iii])\n",
    "# print(step_time_predict[iii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "49\n",
      "[5, 8, 17, 2, 1, 1, 6, 1, 1, 1, 0, 0, 3, 1, 0, 0, 0, 1, 0, 1]\n",
      "20\n",
      "23\n",
      "[4, 6, 8, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "error : \n",
      "total undercount metric 1:\t 0.1416256157635468\n",
      "total overcount metric 1:\t 0.13916256157635468\n",
      "total undercount metric 2:\t 0.046798029556650245\n",
      "total overcount metric 2:\t 0.0603448275862069\n",
      "total undercount metric 3:\t 0.014778325123152709\n",
      "total overcount metric 3:\t 0.02832512315270936\n"
     ]
    }
   ],
   "source": [
    "total_step_count = sum([len(i) for i in step_time_actual])\n",
    "metric1_undercount = 0\n",
    "metric2_undercount = 0\n",
    "metric3_undercount = 0\n",
    "metric1_overcount = 0\n",
    "metric2_overcount = 0\n",
    "metric3_overcount = 0\n",
    "\n",
    "metric2_overcount_list = []\n",
    "metric3_overcount_list = []\n",
    "\n",
    "print(len(test_x))\n",
    "\n",
    "for i in range(len(test_x)):\n",
    "    step_count = len(step_time_actual[i])\n",
    "    undercount = 0\n",
    "    overcount = 0\n",
    "\n",
    "    for j in range(1, step_count):\n",
    "        gap_count = [t for t in step_time_predict[i] if t>=step_time_actual[i][j-1] and t<step_time_actual[i][j]]\n",
    "    #     print(gap_count)\n",
    "        if(len(gap_count)>1):\n",
    "            overcount += len(gap_count)-1\n",
    "        if(len(gap_count)<1):\n",
    "            undercount += 1\n",
    "    gap_count = [t for t in step_time_predict[i] if t>=step_time_actual[i][-1]]\n",
    "    if(len(gap_count)>1):\n",
    "        overcount += len(gap_count)-1\n",
    "    if(len(gap_count)<1):\n",
    "        undercount += 1\n",
    "    \n",
    "    metric1_undercount += undercount\n",
    "    metric1_overcount += overcount\n",
    "    \n",
    "    undercount = 0\n",
    "    overcount = 0\n",
    "    for j in range(1, len(step_time_actual_gap[i])):\n",
    "        gap_count = [t for t in step_time_predict[i] if t>=step_time_actual_gap[i][j-1] and t<step_time_actual_gap[i][j]]\n",
    "    #     print(gap_count)\n",
    "        if(len(gap_count)>1):\n",
    "            overcount += (len(gap_count)-1)\n",
    "        if(len(gap_count)<1):\n",
    "            undercount += 1    \n",
    "    \n",
    "    metric2_undercount += undercount\n",
    "    metric2_overcount += overcount  \n",
    "    metric2_overcount_list.append(overcount)\n",
    "    \n",
    "#     print(undercount, overcount)\n",
    "#     print('undercount : ', undercount*1.0/step_count)\n",
    "#     print('overcount : ', overcount*1.0/step_count)\n",
    "    diff = len(step_time_predict[i])-len(step_time_actual[i])\n",
    "#     if(diff==0):\n",
    "#         print(\"segement correct!\")\n",
    "\n",
    "    if(diff<0):\n",
    "#         print('segement undercount : ', 1-len(step_time_predict[i])*1.0/len(step_time_actual[i]))\n",
    "        metric3_undercount -= diff\n",
    "        metric3_overcount_list.append(0)\n",
    "#     if(diff>=0):\n",
    "    else:\n",
    "#         print('segement overcount : ', 1-len(step_time_actual[i])*1.0/len(step_time_predict[i]))\n",
    "        metric3_overcount += diff\n",
    "        metric3_overcount_list.append(diff)\n",
    "\n",
    "print(len(metric2_overcount_list))\n",
    "print(sum(metric2_overcount_list))\n",
    "print(metric2_overcount_list)\n",
    "print(len(metric3_overcount_list))\n",
    "print(sum(metric3_overcount_list))\n",
    "print(metric3_overcount_list)\n",
    "        \n",
    "print('error : ')\n",
    "print(\"total undercount metric 1:\\t\", metric1_undercount*1.0/total_step_count)\n",
    "print(\"total overcount metric 1:\\t\", metric1_overcount*1.0/total_step_count)\n",
    "print(\"total undercount metric 2:\\t\", metric2_undercount*1.0/total_step_count)\n",
    "print(\"total overcount metric 2:\\t\", metric2_overcount*1.0/total_step_count)\n",
    "print(\"total undercount metric 3:\\t\", metric3_undercount*1.0/total_step_count)\n",
    "print(\"total overcount metric 3:\\t\", metric3_overcount*1.0/total_step_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
